{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh \n",
    "pip install azure-storage-blob azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import threading\n",
    "import asyncio\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient \n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "#from fake_useragent import UserAgent\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "# chrome_options.add_argument(\"start-maximized\")\n",
    "# chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "# chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "# chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "# chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "# chrome_options.add_experimental_option('prefs', {'intl.accept_languages': 'en,en_US'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf677a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.common.by import By\n",
    "# def get_free_proxies(driver):\n",
    "#     driver.get('https://sslproxies.org')\n",
    "\n",
    "#     table = driver.find_element(By.TAG_NAME, 'table')\n",
    "#     thead = table.find_element(By.TAG_NAME, 'thead').find_elements(By.TAG_NAME, 'th')\n",
    "#     tbody = table.find_element(By.TAG_NAME, 'tbody').find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "#     headers = []\n",
    "#     for th in thead:\n",
    "#         headers.append(th.text.strip())\n",
    "\n",
    "#     proxies = []\n",
    "#     for tr in tbody:\n",
    "#         proxy_data = {}\n",
    "#         tds = tr.find_elements(By.TAG_NAME, 'td')\n",
    "#         for i in range(len(headers)):\n",
    "#             proxy_data[headers[i]] = tds[i].text.strip()\n",
    "#         proxies.append(proxy_data)\n",
    "    \n",
    "#     return proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d048046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract inputs \n",
    "list_of_zipcodes = dbutils.widgets.get(\"list_of_zipcode\")\n",
    "list_of_zipcodes = list_of_zipcodes.split(\",\")\n",
    "batch_number = str(dbutils.widgets.get(\"batch_number\"))\n",
    "parent_number = str(dbutils.widgets.get(\"parent_number\"))\n",
    "# url = []\n",
    "# stop_threads_1 = False\n",
    "# stop_threads_2 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %py \n",
    "# def scrape_features(list_of_urls):\n",
    "#     \"\"\"\n",
    "#         input: list of urls: array \n",
    "#         output: CSV: CSV file in designated path; store the data in local disk then transfer over later \n",
    "#     \"\"\"\n",
    "    \n",
    "#     fullpath = '/tmp/' +  datetime.today().strftime('%Y-%m-%d') + str(batch_number) + '.csv'\n",
    "#     with open(fullpath, 'a', newline='') as csvfile:\n",
    "#         fieldnames = [\n",
    "#             \"address\",\n",
    "#             \"State_zipcode\",\n",
    "#             \"last_checked\",\n",
    "#             \"last_updated\",\n",
    "#             \"price\",\n",
    "#             \"bed\", \n",
    "#             \"bath\",\n",
    "#             \"square_footage\",\n",
    "#             \"description\",\n",
    "#             \"status\",\n",
    "#             \"time_on_redfin\",\n",
    "#             \"property_type\",\n",
    "#             \"HOA_dues\",\n",
    "#             \"commission\",\n",
    "#             \"year_built\",\n",
    "#             \"community\",\n",
    "#             \"lot_size\",\n",
    "#             \"MLS\",\n",
    "#             \"list_price\",\n",
    "#             \"ppsf\",\n",
    "#             \"redfin_est\",\n",
    "#             \"style\",\n",
    "#             \"lat\",\n",
    "#             \"long\",\n",
    "#             \"agent_name\",\n",
    "#             \"agent_company\",\n",
    "                    \n",
    "# #                     \"school_name\": school_name, \n",
    "# #                     \"school_review\": school_review,\n",
    "# #                     \"school_num_students\": school_num_students,\n",
    "#             \"url\"\n",
    "#                      ]\n",
    "        \n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "# #         driver = webdriver.Chrome(\"/tmp/chromedriver/chromedriver\", options = chrome_options)\n",
    "#         for single_url in list_of_urls:\n",
    "            \n",
    "# #             global stop_threads_2\n",
    "# #             if stop_threads_2:\n",
    "# #                 break\n",
    "# #             print(\"list of urls\", end=\"\")\n",
    "# #             print(len(list_of_urls[:list_of_urls.index(single_url)+1])/len(list_of_urls))\n",
    "# #             print(list_of_urls.index(url), end='/r')\n",
    "#             print(single_url)\n",
    "#             driver = webdriver.Chrome(\"/tmp/chromedriver/chromedriver\", options = chrome_options)\n",
    "#             driver.get(single_url)\n",
    "            \n",
    "#             try:\n",
    "#                 #Address\n",
    "#                 address = driver.find_element_by_xpath(\"//div[@class='street-address']\").text\n",
    "                \n",
    "#                 #State and zipcode\n",
    "#                 State_zipcode = driver.find_element_by_xpath(\"//div[@class='dp-subtext']\").text\n",
    "\n",
    "#                 #unpack price, bed, bath\n",
    "#                 [price, bed, bath] = [x.text for x in driver.find_elements_by_xpath(\"//div[@class='statsValue']\")]\n",
    "                \n",
    "#                 #square footage\n",
    "#                 square_footage = driver.find_element_by_xpath(\"//span[@class='statsValue']\").text\n",
    "                \n",
    "#                 #description - if continue reading click drop down \n",
    "#                 description = None \n",
    "#                 try:\n",
    "#                     description = driver.find_element_by_xpath(\"//p[@class='text-base']//span\").text\n",
    "#                 except Exception as e: \n",
    "#                     print(\"no description\")\n",
    "                    \n",
    "#                 #redfin last checked \n",
    "#                 last_checked = driver.find_element_by_xpath(\"//div[@class='data-quality']/a\").text\n",
    "                \n",
    "#                 #last updated \n",
    "#                 last_updated = driver.find_elements_by_xpath(\"//div[@class='data-quality']\")[-1].text\n",
    "                \n",
    "# #                 print(last_checked, last_updated)\n",
    "#                 #nullify all inital values\n",
    "#                 status, time_on_redfin, property_type, HOA_dues, year_built, community, lot_size, MLS, list_price, ppsf, redfin_est, style, commission = (None,)*13\n",
    "\n",
    "#                 #list of home_facts  \n",
    "#                 home_facts = driver.find_elements_by_xpath(\"//div[@class='keyDetail font-weight-roman font-size-base']//span\")\n",
    "                \n",
    "#                 for i in range(len(home_facts)):\n",
    "#                     text = home_facts[i].text\n",
    "                    \n",
    "#                     if text == \"Status\":\n",
    "#                         status = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"Time on Redfin\": \n",
    "#                         time_on_redfin = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"Property Type\":\n",
    "#                         property_type = home_facts[i+1].text\n",
    "#                     elif text == \"HOA Dues\":\n",
    "#                         HOA_dues = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"Year Built\":\n",
    "#                         year_built = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"Community\":\n",
    "#                         community = home_facts[i+1].text\n",
    "                        \n",
    "#                     elif text == \"Lot Size\":\n",
    "#                         lot_size = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"MLS#\":\n",
    "#                         MLS = home_facts[i+1].text\n",
    "                        \n",
    "#                     elif text == \"List Price\":\n",
    "#                         list_price = home_facts[i+1].text\n",
    "                        \n",
    "#                     elif text == \"Price/Sq.Ft.\":\n",
    "#                         ppsf = home_facts[i+1].text\n",
    "                        \n",
    "#                     elif text == \"Redfin Estimate\":\n",
    "#                         redfin_est = home_facts[i+1].text\n",
    "                    \n",
    "#                     elif text == \"Style\":\n",
    "#                         style = home_facts[i+1].text\n",
    "                        \n",
    "#                     elif text == \"Buyer's Brokerage Commission\":\n",
    "#                         commission = home_facts[i+1].text\n",
    "                \n",
    "#                 #lat\n",
    "#                 lat = json.loads(driver.find_element_by_xpath(\"//div[@class='Section AddressBannerSectionV2 white-bg not-omdp']//script\").get_attribute('innerHTML'))[\"geo\"][\"latitude\"]\n",
    "#                 #long\n",
    "#                 long = json.loads(driver.find_element_by_xpath(\"//div[@class='Section AddressBannerSectionV2 white-bg not-omdp']//script\").get_attribute('innerHTML'))[\"geo\"][\"longitude\"]\n",
    "                \n",
    "# #                 print(\"4\")\n",
    "#                 #agent name\n",
    "#                 agent_name = None \n",
    "#                 try: \n",
    "#                     agent_name = driver.find_element_by_xpath(\"//span[@class='agent-name']\").text\n",
    "#                 except Exception as e: \n",
    "#                     print(\"no agent name\")\n",
    "                \n",
    "# #                 #agent company\n",
    "#                 agent_company = None\n",
    "#                 try:\n",
    "#                     agent_company = driver.find_element_by_xpath(\"//div[@class='aaq-question-stage-agent-info']//div\").text\n",
    "#                 except Exception as e: \n",
    "#                     print(\"no agent company\")\n",
    "                \n",
    "# #               #school name\n",
    "# #                 school_name = None\n",
    "# #                 try:\n",
    "# #                     school_name = driver.find_element_by_xpath(\"//div[@class='school-name font-size-base font-weight-bold']\").get_attribute('innerHTML')\n",
    "# #                 except Exception as e: \n",
    "# #                     print(\"no school name\")\n",
    "\n",
    "#                 #school review\n",
    "# #                 school_review = None \n",
    "# #                 try:\n",
    "# #                     school_review = driver.find_element_by_xpath(\"//div[@class='gs-rating-text']\").get_attribute('innerHTML')\n",
    "# #                 except Exception as e: \n",
    "# #                     print(\"no school review\")\n",
    "                \n",
    "                \n",
    "#                 #number of student\n",
    "# #                 school_num_students = None \n",
    "# #                 try: \n",
    "# #                     school_num_students = driver.find_element_by_xpath(\"//div[@class='subsection-number']\").get_attribute('innerHTML')\n",
    "# #                 except Exception as e: \n",
    "# #                     print(\"no num of students\")\n",
    "            \n",
    "                    \n",
    "                \n",
    "#                 list_table = { \n",
    "#                     \"address\": address, \n",
    "#                     \"State_zipcode\":State_zipcode,\n",
    "#                     \"last_checked\":last_checked,\n",
    "#                     \"last_updated\":last_updated,\n",
    "#                     \"price\":price,\n",
    "#                     \"bed\":bed, \n",
    "#                     \"bath\":bath,\n",
    "#                     \"square_footage\":square_footage,\n",
    "#                     \"description\":description,\n",
    "#                     \"status\":status,\n",
    "#                     \"time_on_redfin\":time_on_redfin,\n",
    "#                     \"property_type\":property_type,\n",
    "#                     \"HOA_dues\":HOA_dues,\n",
    "#                     \"commission\":commission,\n",
    "#                     \"year_built\":year_built,\n",
    "#                     \"community\":community,\n",
    "#                     \"lot_size\":lot_size,\n",
    "#                     \"MLS\":MLS,\n",
    "#                     \"list_price\":list_price,\n",
    "#                     \"ppsf\":ppsf,\n",
    "#                     \"redfin_est\":redfin_est,\n",
    "#                     \"style\":style,\n",
    "#                     \"lat\":lat,\n",
    "#                     \"long\":long,\n",
    "#                     \"agent_name\":agent_name,\n",
    "#                     \"agent_company\":agent_company,\n",
    "                    \n",
    "# #                     \"school_name\": school_name, \n",
    "# #                     \"school_review\": school_review,\n",
    "# #                     \"school_num_students\": school_num_students,\n",
    "#                     \"url\":single_url\n",
    "#                 }\n",
    "                \n",
    "#                 writer.writerow(list_table)\n",
    "        \n",
    "#             except Exception as e:\n",
    "#                 print(e, single_url)\n",
    "                \n",
    "#             driver.close()\n",
    "        \n",
    "# #         driver.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4610d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%py\n",
    "def scrape_urls(list_of_zipcodes):\n",
    "    \"\"\"\n",
    "    input: list of zipcodes; array \n",
    "    output: list of real estate urls; array\n",
    "    \n",
    "    \"\"\"\n",
    "#     print(list_of_zipcodes)\n",
    "#     global url\n",
    "    url = []\n",
    "    for zipcode in list_of_zipcodes: \n",
    "        \n",
    "#         global stop_threads_1\n",
    "#         if stop_threads_1: \n",
    "#             break\n",
    "        #print(\"urls\", end=\"\")\n",
    "        #print(len(list_of_zipcodes[:list_of_zipcodes.index(zipcode)+1])/len(list_of_zipcodes))\n",
    "        print(zipcode)\n",
    "        driver = webdriver.Chrome(\"/tmp/chromedriver/chromedriver\",options=chrome_options)\n",
    "        driver.get(f\"https://www.redfin.com/zipcode/{zipcode}\")\n",
    "        try:\n",
    "            url += [x.get_attribute(\"href\") for x in driver.find_elements_by_xpath(\"//div[@class='PhotoSlider photoContainer']//a\")]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try: \n",
    "            total_pages = [x.get_attribute(\"href\") for x in driver.find_elements_by_xpath(\"//a[@class='clickable goToPage']\")]\n",
    "\n",
    "            if total_pages and len(total_pages)>=1: \n",
    "                for page in total_pages:\n",
    "                    driver.get(page)\n",
    "                    url += [x.get_attribute(\"href\") for x in driver.find_elements_by_xpath(\"//div[@class='PhotoSlider photoContainer']//a\")]\n",
    "            driver.close()\n",
    "            \n",
    "\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            \n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to transfer local tmp file to filestore \n",
    "# def tmp_to_filestore():\n",
    "#     \"\"\"\n",
    "#     input: today's scraped tmp file \n",
    "#     output: boolean \n",
    "#     \"\"\"\n",
    "#     origin = \"file:/tmp/\" + path +  datetime.today().strftime('%Y-%m-%d')+'.csv'\n",
    "#     dest = \"file:/dbfs/FileStore/\" + datetime.today().strftime('%Y-%m-%d')+'.csv'\n",
    "#     dbutils.fs.mv(origin , dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359750e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %py\n",
    "\n",
    "# final_url = scrape_urls(list_of_zipcodes)\n",
    "# scrape_features(final_url)\n",
    "\n",
    "\n",
    "#main functions to execute in thread\n",
    "# t1 = threading.Thread(target=scrape_urls, args=[list_of_zipcodes, ])\n",
    "# t2 = threading.Thread(target=scrape_features, args=[url, ])\n",
    "# t1.start()\n",
    "# while True: \n",
    "#     if len(url)!=0: \n",
    "#         break\n",
    "# t2.start()\n",
    "# t1.join()\n",
    "# t2.join()\n",
    "\n",
    "# executors_list = []\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "#     executors_list.append(executor.submit(scrape_urls, list_of_zipcodes))\n",
    "#     while True: \n",
    "#         if len(url)!=0: \n",
    "#             break\n",
    "#     executors_list.append(executor.submit(scrape_features, url))\n",
    "\n",
    "# for x in executors_list:\n",
    "#     print(x.result())\n",
    "\n",
    "\n",
    "# from multiprocessing import Process\n",
    "\n",
    "# p = Process(target=scrape_urls, args=(list_of_zipcodes, ))\n",
    "# p.start()\n",
    "# while True:\n",
    "#     if len(url)!=0:\n",
    "#         break\n",
    "# p2 = Process(target=scrape_features, args=(url, ))\n",
    "# p2.start()\n",
    "# p.join()\n",
    "# p2.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thread control \n",
    "# stop_threads_1 = True\n",
    "# t1.join()\n",
    "# stop_threads_2 = True\n",
    "# t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "input: list of urls: array \n",
    "output: CSV: CSV file in designated path; store the data in local disk then transfer over later \n",
    "\"\"\"\n",
    "\n",
    "def scrape_features(list_of_urls):\n",
    "\n",
    "    \n",
    "    fullpath = '/tmp/' +  datetime.today().strftime('%Y-%m') + \"-\" +str(parent_number) + \"-\" + str(batch_number) + '.csv'\n",
    "    with open(fullpath, 'a', newline='') as csvfile:\n",
    "        fieldnames = [\"address\",\"State_zipcode\",\"last_checked\",\"last_updated\",\"price\",\"bed\",\"bath\",\n",
    "                      \"square_footage\",\"description\",\"status\",\"time_on_redfin\",\"property_type\",\"HOA_dues\",\n",
    "                      \"commission\",\"year_built\",\"community\",\"lot_size\",\"MLS\",\"list_price\",\"ppsf\",\"redfin_est\",\n",
    "                      \"walk\",\"train\",\"bike\",\"act_views\",\"act_favs\",\"act_outs\",\"act_tours\",\"mkt_score\",\n",
    "                      \"mkt_rating\", \"pub_beds\",\"pub_baths\",\"pub_fin_sqft\",\"pub_unfin_sqft\",\"pub_total_sqft\",\n",
    "                      \"pub_stories\",\"pub_lot_size\",\"pub_style\",\"pub_yr_built\",\"pub_yr_reno\",\"pub_county\",\n",
    "                      \"pub_apn\", \"style\",\"lat\",\"long\",\"agent_name\",\"agent_company\",\"url\"\n",
    "                     ]\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "\n",
    "#         driver = webdriver.Chrome(\"/tmp/chromedriver/chromedriver\", options = chrome_options)\n",
    "        for single_url in list_of_urls:\n",
    "            \n",
    "#             global stop_threads_2\n",
    "#             if stop_threads_2:\n",
    "#                 break\n",
    "            print(single_url)\n",
    "#             print(\"list of urls\", end=\"\")\n",
    "#             print(len(list_of_urls[:list_of_urls.index(single_url)+1])/len(list_of_urls))\n",
    "#             print(list_of_urls.index(url), end='/r')\n",
    "            driver = webdriver.Chrome(\"/tmp/chromedriver/chromedriver\", options = chrome_options)\n",
    "            driver.get(single_url)\n",
    "            \n",
    "            # ADDRESS SCRAPE\n",
    "            try:\n",
    "                address = driver.find_element_by_xpath(\"//div[@class='street-address']\").text\n",
    "            except NoSuchElementException:\n",
    "                address = driver.find_element_by_xpath(\"//meta[@name='twitter:text:street_address']\").get_attribute(\"content\")\n",
    "            except Exception:    \n",
    "                address = None\n",
    "                print(\"no address, \" + single_url)\n",
    "            \n",
    "            # STATE/ZIPCODE SCRAPE\n",
    "            try:\n",
    "                State_zipcode = driver.find_element_by_xpath(\"//div[@class='dp-subtext']\").text\n",
    "            except:\n",
    "                State_zipcode = None\n",
    "                print(\"no state/zip, \" + single_url)\n",
    "                \n",
    "            # PRICE/BED/BATH SCRAPE\n",
    "            try:\n",
    "                element_pricebedsbath = driver.find_elements_by_xpath(\"//div[@class='statsValue']\")\n",
    "                price = element_pricebedsbath[0].text\n",
    "                bed   = element_pricebedsbath[1].text\n",
    "                bath  = element_pricebedsbath[2].text\n",
    "            except:\n",
    "                price = None\n",
    "                bed   = None\n",
    "                bath  = None\n",
    "                print(\"no price/bed/bath, \" + single_url)\n",
    "                \n",
    "            # SQUARE FOOTAGE SCRAPE\n",
    "            try:\n",
    "                square_footage = driver.find_element_by_xpath(\"//span[@class='statsValue']\").text\n",
    "            except NoSuchElementException:\n",
    "                square_footage = driver.find_element_by_xpath(\"//meta[@name='twitter:text:sqft']\").get_attribute(\"content\")          \n",
    "            except Exception:\n",
    "                square_footage = None\n",
    "                print(\"no square footage, \" + single_url)\n",
    "                                \n",
    "            # DESCRIPTION SCRAPE\n",
    "            try:\n",
    "                description = driver.find_element_by_xpath(\"//p[@class='text-base']//span\").text\n",
    "            except NoSuchElementException:\n",
    "                description = driver.find_element_by_xpath('//meta[@name=\"twitter:text:description_simple\"]').get_attribute(\"content\")\n",
    "            except Exception:\n",
    "                description = None\n",
    "                print(\"no description, \" + single_url)\n",
    "                    \n",
    "            # LAST CHECKED SCRAPE\n",
    "            try:\n",
    "                last_checked = driver.find_element_by_xpath(\"//div[@class='data-quality']/a\").text\n",
    "            except:\n",
    "                last_checked = None\n",
    "                print(\"no last checked, \" + single_url)\n",
    "                \n",
    "            # LAST UPDATED SCRAPE\n",
    "            try:\n",
    "                last_updated = driver.find_elements_by_xpath(\"//div[@class='data-quality']\")[-1].text\n",
    "            except NoSuchElementException:\n",
    "                element_last_update = driver.find_element_by_xpath('//div[@class=\"listingInfoSection font-color-gray-dark\"]//div')\n",
    "                checked, updated = element_last_update.text.split(' | ')\n",
    "                last_updated = updated.replace('Last updated ', '')\n",
    "            except Exception:\n",
    "                last_updated = None\n",
    "                print(\"last updated, \" + single_url)\n",
    "                \n",
    "            # HOME FACTS TABLE SCRAPE\n",
    "            home_facts = driver.find_elements_by_xpath(\"//div[@class='keyDetail font-weight-roman font-size-base']//span\")\n",
    "            \n",
    "            # NULL all inital values\n",
    "            status, time_on_redfin, property_type, HOA_dues, year_built, community, lot_size, MLS, list_price, ppsf, redfin_est, style, commission = (None,)*13\n",
    "                \n",
    "            for i in range(len(home_facts)):\n",
    "                text = home_facts[i].text\n",
    "        \n",
    "                if text == \"Status\":\n",
    "                    status = home_facts[i+1].text\n",
    "                elif text == \"Time on Redfin\": \n",
    "                    time_on_redfin = home_facts[i+1].text\n",
    "                elif text == \"Property Type\":\n",
    "                    property_type = home_facts[i+1].text\n",
    "                elif text == \"HOA Dues\":\n",
    "                    HOA_dues = home_facts[i+1].text\n",
    "                elif text == \"Year Built\":\n",
    "                    year_built = home_facts[i+1].text\n",
    "                elif text == \"Community\":\n",
    "                    community = home_facts[i+1].text\n",
    "                elif text == \"Lot Size\":\n",
    "                    lot_size = home_facts[i+1].text\n",
    "                elif text == \"MLS#\":\n",
    "                    MLS = home_facts[i+1].text\n",
    "                elif text == \"List Price\":\n",
    "                    list_price = home_facts[i+1].text\n",
    "                elif text == \"Price/Sq.Ft.\":\n",
    "                    ppsf = home_facts[i+1].text\n",
    "                elif text == \"Redfin Estimate\":\n",
    "                    redfin_est = home_facts[i+1].text\n",
    "                elif text == \"Style\":\n",
    "                    style = home_facts[i+1].text\n",
    "                elif text == \"Buyer's Brokerage Commission\":\n",
    "                    commission = home_facts[i+1].text\n",
    "            \n",
    "            # TRANSPORTATION SCRAPE\n",
    "            try:\n",
    "                transport      = driver.find_elements_by_xpath('//div[@data-rf-test-name=\"ws-percentage\"]')\n",
    "                walk1, walk2   = transport[0].text.split('/')\n",
    "                train1, train2 = transport[1].text.split('/')\n",
    "                bike1, bike2   = transport[2].text.split('/')\n",
    "\n",
    "                ## this will create a percentage of the commuting scores\n",
    "                walk1  = float(walk1)\n",
    "                walk2  = float(walk2)\n",
    "                walk   = walk1/walk2\n",
    "                train1 = float(train1)\n",
    "                train2 = float(train2)\n",
    "                train  = train1/train2\n",
    "                bike1  = float(bike1)\n",
    "                bike2  = float(bike2)\n",
    "                bike   = bike1/bike2\n",
    "            except:\n",
    "                walk   = None\n",
    "                train  = None\n",
    "                bike   = None\n",
    "                print(\"no transport, \" + single_url)\n",
    "            \n",
    "            # ACTIVITY\n",
    "            try:\n",
    "                activity  = driver.find_elements_by_xpath(\"//div[@class='upperLabel']//span[@data-rf-test-name='activity-count-label']\")\n",
    "                act_views = activity[0].text\n",
    "                act_fav   = activity[1].text\n",
    "                act_outs  = activity[2].text\n",
    "                act_tours = activity[3].text\n",
    "            except:\n",
    "                act_views = None\n",
    "                act_fav   = None\n",
    "                act_outs  = None\n",
    "                act_tours = None\n",
    "                print(\"no activity, \" + single_url)               \n",
    "            \n",
    "            # MARKET SCORE/COMPETITION SCRAPE\n",
    "            try:\n",
    "                market = driver.find_element_by_xpath(\"//div[@class='scoreTM']\")\n",
    "                score_x, rating_x, redfin_x = market.text.split('\\n')\n",
    "                mkt_score  = score_x\n",
    "                mkt_rating = rating_x\n",
    "            except:\n",
    "                print(\"no mkt comp, \" + single_url)\n",
    "                mkt_score  = None     \n",
    "                mkt_rating = None\n",
    "                \n",
    "            # PUBLIC FACTS TABLE SCRAPE\n",
    "            public_facts = driver.find_elements_by_xpath('//div[@class=\"facts-table\"]//div[@class=\"table-row\"]')\n",
    "\n",
    "            # NULL all inital values\n",
    "            beds1, baths1, fin_sqft, unfin_sqft, total_sqft, stories, lot_size, style, yr_built, yr_reno, county, apn = (None,)*12\n",
    "            \n",
    "            # this will iterate the table and assign the values to appropriate variables\n",
    "            for idx, data in enumerate(public_facts):\n",
    "                # data contains both the field and the value\n",
    "                # this will split the data into 2 variables\n",
    "                field, value = public_facts[idx].text.split('\\n')\n",
    "\n",
    "                if field == \"Beds\":\n",
    "                    beds1 = value\n",
    "                elif field == \"Baths\":\n",
    "                    baths1 = value\n",
    "                elif field == \"Finished Sq. Ft.\":\n",
    "                    fin_sqft = value\n",
    "                elif field == \"Unfinished Sq. Ft.\":\n",
    "                    unfin_sqft = value\n",
    "                elif field == \"Total Sq. Ft.\":\n",
    "                    total_sqft = value\n",
    "                elif field == \"Stories\":\n",
    "                    stories = value\n",
    "                elif field == \"Lot Size\":\n",
    "                    lot_size = value\n",
    "                elif field == \"Style\":\n",
    "                    style = value\n",
    "                elif field == \"Year Built\":\n",
    "                    yr_built = value\n",
    "                elif field == \"Year Renovated\":\n",
    "                    yr_reno = value\n",
    "                elif field == \"County\":\n",
    "                    county = value\n",
    "                elif field == \"APN\":\n",
    "                    apn = value\n",
    "\n",
    "            # now we append to add all values including blanks for the listing\n",
    "            pub_beds       = beds1\n",
    "            pub_baths      = baths1\n",
    "            pub_fin_sqft   = fin_sqft\n",
    "            pub_unfin_sqft = unfin_sqft\n",
    "            pub_total_sqft = total_sqft\n",
    "            pub_stories    = stories\n",
    "            pub_lot_size   = lot_size\n",
    "            pub_style      = style\n",
    "            pub_yr_built   = yr_built\n",
    "            pub_yr_reno    = yr_reno\n",
    "            pub_county     = county\n",
    "            pub_apn        = apn\n",
    "            \n",
    "            # LAT/LONG\n",
    "            try:\n",
    "                lat = json.loads(driver.find_element_by_xpath(\"//div[@class='Section AddressBannerSectionV2 white-bg not-omdp']//script\").get_attribute('innerHTML'))[\"geo\"][\"latitude\"]\n",
    "                long = json.loads(driver.find_element_by_xpath(\"//div[@class='Section AddressBannerSectionV2 white-bg not-omdp']//script\").get_attribute('innerHTML'))[\"geo\"][\"longitude\"]\n",
    "            except NoSuchElementException:\n",
    "                geo_position = driver.find_element_by_xpath('//meta[@name=\"geo.position\"]').get_attribute(\"content\")\n",
    "                lat_temp, long_temp = geo_position.split(\";\")\n",
    "                lat  = float(lat_temp)\n",
    "                long = float(long_temp)\n",
    "            except Exception:\n",
    "                lat  = None\n",
    "                long = None\n",
    "                print(\"no lat/long, \" + single_url)\n",
    "                \n",
    "            # AGENT NAME\n",
    "            try: \n",
    "                agent_name = driver.find_element_by_xpath(\"//span[@class='agent-name']\").text\n",
    "            except:\n",
    "                agent_name = None \n",
    "                print(\"no agent name, \" + single_url)\n",
    "                \n",
    "            # AGENT COMPANY\n",
    "            try:\n",
    "                agent_company = driver.find_element_by_xpath(\"//div[@class='aaq-question-stage-agent-info']//div\").text\n",
    "            except:\n",
    "                agent_company = None\n",
    "                print(\"no agent company, \" + single_url)\n",
    "                \n",
    "            # PROPERTY DETAILS\n",
    "#             try:\n",
    "#                 property_details = driver.find_element_by_xpath('//*[@id=\"propertyDetails-collapsible\"]/div[2]/div/div/div[1]').text\n",
    "#             except:\n",
    "#                 property_details = None\n",
    "                    \n",
    "            list_table = { \n",
    "                \"address\":address,\"State_zipcode\":State_zipcode,\"last_checked\":last_checked,\n",
    "                \"last_updated\":last_updated,\"price\":price,\"bed\":bed,\"bath\":bath,\n",
    "                \"square_footage\":square_footage,\"description\":description,\"status\":status,\n",
    "                \"time_on_redfin\":time_on_redfin,\"property_type\":property_type,\"HOA_dues\":HOA_dues,\n",
    "                \"commission\":commission,\"year_built\":year_built,\"community\":community,\"lot_size\":lot_size,\n",
    "                \"MLS\":MLS,\"list_price\":list_price,\"ppsf\":ppsf,\"redfin_est\":redfin_est,\"walk\":walk,\n",
    "                \"train\":train,\"bike\":bike, \"act_views\":act_views,\"act_favs\":act_fav,\"act_outs\":act_outs,\n",
    "                \"act_tours\":act_tours,\"mkt_score\":mkt_score,\"mkt_rating\":mkt_rating,\"pub_beds\":pub_beds,\n",
    "                \"pub_baths\":pub_baths,\"pub_fin_sqft\":pub_fin_sqft,\"pub_unfin_sqft\":pub_unfin_sqft,\n",
    "                \"pub_total_sqft\":pub_total_sqft,\"pub_stories\":pub_stories,\"pub_lot_size\":pub_lot_size,\n",
    "                \"pub_style\":pub_style,\"pub_yr_built\":pub_yr_built,\"pub_yr_reno\":pub_yr_reno,\n",
    "                \"pub_county\":pub_county,\"pub_apn\":pub_apn,\"style\":style,\"lat\":lat,\"long\":long,\n",
    "                \"agent_name\":agent_name,\"agent_company\":agent_company,\n",
    "                \"url\":single_url\n",
    "                }\n",
    "                \n",
    "            writer.writerow(list_table)\n",
    "                \n",
    "            driver.close()\n",
    "        \n",
    "    print(\"complete!\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = [\"address\",\"State_zipcode\",\"last_checked\",\"last_updated\",\"price\",\"bed\",\"bath\",\n",
    "                      \"square_footage\",\"description\",\"status\",\"time_on_redfin\",\"property_type\",\"HOA_dues\",\n",
    "                      \"commission\",\"year_built\",\"community\",\"lot_size\",\"MLS\",\"list_price\",\"ppsf\",\"redfin_est\",\n",
    "                      \"walk\",\"train\",\"bike\",\"act_views\",\"act_favs\",\"act_outs\",\"act_tours\",\"mkt_score\",\n",
    "                      \"mkt_rating\", \"pub_beds\",\"pub_baths\",\"pub_fin_sqft\",\"pub_unfin_sqft\",\"pub_total_sqft\",\n",
    "                      \"pub_stories\",\"pub_lot_size\",\"pub_style\",\"pub_yr_built\",\"pub_yr_reno\",\"pub_county\",\n",
    "                      \"pub_apn\", \"style\",\"lat\",\"long\",\"agent_name\",\"agent_company\",\"property_details\",\"url\"\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_csv(path=\"/tmp/\", extension =\"csv\"):\n",
    "    os.chdir(path)\n",
    "    result = glob.glob(\"*.{}\".format(extension))\n",
    "    return result\n",
    "\n",
    "\n",
    "def upload_blob():\n",
    "    #create a container \n",
    "    blob = BlobServiceClient(storage_account_url, STORAGEACCOUNTKEY)\n",
    "    \n",
    "    #container name will be today's date \n",
    "    container_name = 'container-redfinextract-' +datetime.today().strftime('%Y-%m')\n",
    "    \n",
    "    container_list = []\n",
    "    \n",
    "    for container in blob.list_containers(): \n",
    "        container_list.append(container[\"name\"])\n",
    "    \n",
    "    if container_name not in container_list:\n",
    "        blob.create_container(container_name)\n",
    "    \n",
    "    #connect to container\n",
    "    connection_string = f\"DefaultEndpointsProtocol=https;AccountName={STORAGEACCOUNTNAME};AccountKey={STORAGEACCOUNTKEY};EndpointSuffix=core.windows.net\"\n",
    "    \n",
    "    container = ContainerClient.from_connection_string(conn_str=connection_string, container_name=container_name)\n",
    "    \n",
    "    for csv_file in get_csv():\n",
    "        df = pd.read_csv(f\"/tmp/{csv_file}\", names = fieldnames)\n",
    "    \n",
    "        container.upload_blob(name = csv_file, data = df.to_csv())\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
